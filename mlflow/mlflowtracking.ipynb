{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# machine learning life cycle management\n",
    "\n",
    "There are certain steps that a data science team go through to develope an AI product. Even though the team is highliy skilled in Machine learning and Deep learning the team still fails to provide a practical business value. \n",
    "\n",
    "A summary of this cycle is showin in the picture below:      \n",
    "1. Scope:       \n",
    "What are the most preiority usecases?      \n",
    "2. Understand:         \n",
    "What dataset is needd to implement those usecases?      \n",
    "3. Build:        \n",
    "What toold are relevent to this problem? (Data prepration, feature engneering, model training and building)           \n",
    "4. Run:          \n",
    "How to track versions of models and be able to compare then as needed?           \n",
    "5. Manage:           \n",
    "How to ensure high performance via monitoring and retraining?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1000/1*fIvkxCBqWZB6-ukShpjvRA.jpeg\">       \n",
    "\n",
    "Image source and read more \\[2\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "- MLflow\n",
    "- Kubeflow\n",
    "- DVC\n",
    "- Sacred\n",
    "- TensorFlow Extended\n",
    "- Apache Beam\n",
    "- KNIME Analytics PLatform\n",
    "- H2O and Sparkling Water        \n",
    "Learn more about their differences \\[1\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow offers four components:\n",
    "* MLflow Tracking      \n",
    "Record and query experiments: code, data, config, and results \n",
    "* MLflow Projects      \n",
    "Package data science code in a format to reproduce runs on any platform\n",
    "* MLflow Models     \n",
    "Deploy machine learning models in diverse serving environments\n",
    "* Model Registry     \n",
    "Store, annotate, discover, and manage models in a central repository \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although all of these components plays an important role in the Machine learning life cycle, I am only covering how to use MLflow Tracking here. \n",
    "\n",
    "During developing your Machine learning/Deep learning project, whether your building an AI business product or doing academic research, you have probably came around the problem of keep tracking of your results. A common solution while running your experiments for several times is often an excel sheet to store your latest results. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*aiYtp8fqIIFFeWFR1My5gg.png\">\n",
    "\n",
    "picture source \\[3\\]\n",
    "\n",
    "This is not a practical solution as your project and the number of paramters your keeping track of start to grow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow\n",
    "- open source platform\n",
    "- mlFlow is a framework that supports the machine learning lifecycle\n",
    "- it has components to monitor your model during training and running\n",
    "- platform for managing the end-to-end machine learning lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tcv85tVhIq9B"
   },
   "source": [
    "# MLflow Tracking\n",
    "*  API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results\n",
    "* MLflow Tracking lets you log and query experiments using [Python](https://www.mlflow.org/docs/latest/python_api/index.html#python-api), [REST](https://www.mlflow.org/docs/latest/rest-api.html#rest-api), [R API](https://www.mlflow.org/docs/latest/R-api.html#r-api), and [Java API](https://www.mlflow.org/docs/latest/java_api/index.html#java-api) APIs\n",
    "* allows us to compare the results from multiple runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_HMeUF1IvoW"
   },
   "source": [
    "## 1. [Concepts](https://www.mlflow.org/docs/latest/tracking.html#concepts)\n",
    "MLflow Tracking is organized around the concept of runs.\n",
    "\n",
    "Each run record these information:\n",
    "* **Start and End Time**\n",
    "* **Source **        \n",
    "name of the file you launch the run\n",
    "* **Parameters**      \n",
    "Key-value input parameters of your choice      \n",
    "Both keys and values are strings\n",
    "* **Metrics**     \n",
    "Key-value metrics    \n",
    "value is numeric  \n",
    "Each metric can be updated throughout the course of the run (for example, to track how your model’s loss function is converging), and MLflow records and lets you visualize the metric’s full history.\n",
    "* **Tags**     \n",
    "Key-Value run metadata than can be updated during and after a run completes.          \n",
    "both key and value are strings.\n",
    "* **Artifacts**    \n",
    "Output files in any format.      \n",
    "For example: images (PNGs), models (a pickled scikit-learn model), and data files (a Parquet file) as artifacts.\n",
    "\n",
    "\n",
    " The experiment UI lets you perform the following key tasks:\n",
    "* List and compare runs\n",
    "* Search for runs by parameter or metric value\n",
    "* Visualize run metrics\n",
    "* Download run results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4SoW_0OIzaH"
   },
   "source": [
    "## 2. [Where Runs are recorded?](https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded)\n",
    "MLflow runs can be recorded to local files, to a SQLAlchemy compatible database, or remotely to a tracking server.\n",
    "\n",
    "By default, the MLflow Python API logs runs locally to files in an mlruns directory wherever you ran your program.\n",
    "\n",
    "You can then run mlflow ui to see the logged runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XuRGsjKYI6oZ"
   },
   "source": [
    "## 3. [Log Data to Runs](https://www.mlflow.org/docs/latest/tracking.html#logging-data-to-runs) (MLflow Python)\n",
    "3.1 Logging Functions\n",
    "\n",
    "3.2 Launching Multiple Runs in One Program\n",
    "\n",
    "3.3 Performance Tracking with Metrics\n",
    "\n",
    "3.4 Visualizing Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n77y26ocNfwq"
   },
   "source": [
    "### 3.1 Logging Functions\n",
    "`mlflow.set_tracking_uri()`\n",
    "* connects to a tracking URI \n",
    "* URI can be HTTp/HTTPS URI for a remote server\n",
    "* A database connection set_tracking_uri\n",
    "* local path to log data to a directory\n",
    "* Default URI: `mlruns`\n",
    "\n",
    "`mlflow.create_experiment()`\n",
    "* creates a new experiment and returns its ID\n",
    "\n",
    "`mlflow.set_experiment()`\n",
    "* sets an experiment as active\n",
    "* If the experiment does not exist, creates a new experiment. \n",
    "\n",
    "`mlflow.start_run()`\n",
    "* returns the currently active run (if one exists), or start a new run.\n",
    "\n",
    "`mlflow.end_run()`\n",
    "* ends the currenly active run.\n",
    "\n",
    "`mlflow.log_param()`\n",
    "* logs a single key-value param in the currently active run\n",
    "*  Use `mlflow.log_params()` to log multiple params at once.\n",
    "\n",
    "`mlflow.log_metric()`\n",
    "* logs a single key-value metric\n",
    "* Use `mlflow.log_metrics()` to log multiple metrics at once\n",
    "\n",
    "`mlflow.set_tag()`\n",
    "* sets a single key-value tag in the currently active run\n",
    "* Use `mlflow.set_tags()` to set multiple tags at once\n",
    "\n",
    "`mlflow.log_artifact()`\n",
    "* logs a local file or directory as an artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mh8SgwnII_TC"
   },
   "source": [
    "## 4. Organizing Runs in Experiments\n",
    "MLflow allows you to group runs under experiments, which can be useful for comparing runs intended to tackle a particular task.\n",
    "\n",
    "[read more](https://www.mlflow.org/docs/latest/tracking.html#organizing-runs-in-experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Lm98ynvJLDB"
   },
   "source": [
    "## 5. [Tracking UI](https://www.mlflow.org/docs/latest/tracking.html#tracking-ui)\n",
    "The UI contains the following key features:\n",
    "* Experiment-based run listing and comparison\n",
    "* Searching for runs by parameter or metric value\n",
    "* Visualizing run metrics\n",
    "* Downloading run results\n",
    "\n",
    "\n",
    "\n",
    "[viewing the tracking UI](https://www.mlflow.org/docs/latest/quickstart.html#viewing-the-tracking-ui)       \n",
    "\n",
    "**Local**       \n",
    "in the project directory run:     \n",
    "bash-> `mlflow ui`     \n",
    "view your experiments and runs:     \n",
    "`http://localhost:5000`\n",
    "\n",
    "\n",
    "**On server**      \n",
    "Server Bash->     `env/bin/mlflow ui --host $(hostname -f)`       \n",
    "This command outputs a url with http:// at the begininig.(gives you an ip address)      \n",
    "Remove the http (keep the ip and port)      \n",
    "Put the ip and port in a local terminal in the following format:     \n",
    "Local bash->     `ssh -L <localport>:<ip>:<port> username@servername` (this port is usually 5000)     \n",
    "view your experiments and runs:     \n",
    "Local Browser-> `http://localhost:5000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri = 'mlruns/'\n",
    "experiment_name = \"mltest\"\n",
    "run_name = 'run0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1599592039213,
     "user": {
      "displayName": "Fatemeh Rahimi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIPmO3uzCLVsiQVblP4W1c4qj3-XpxbhpaPBi=s64",
      "userId": "09649316258388689485"
     },
     "user_tz": 180
    },
    "id": "qOCCekVQsvv0",
    "outputId": "8d69734a-f6ca-400b-e3ca-35bc567304ea",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Running mlflow_tracking.py\n"
    }
   ],
   "source": [
    "import os\n",
    "from random import random, randint\n",
    "\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# with mlflow.start_run(run_name='arima_param'):\n",
    "mlflow.start_run(run_name=run_name, nested=True)\n",
    "\n",
    "print(\"Running mlflow_tracking.py\")\n",
    "\n",
    "log_param(\"param1\", randint(0, 100))\n",
    "\n",
    "log_metric(\"foo\", random())\n",
    "log_metric(\"foo\", random() + 1)\n",
    "log_metric(\"foo\", random() + 2)\n",
    "\n",
    "if not os.path.exists(\"outputs\"):\n",
    "    os.makedirs(\"outputs\")\n",
    "with open(\"outputs/test.txt\", \"w\") as f:\n",
    "    f.write(\"hello world!\")\n",
    "\n",
    "log_artifacts(\"outputs\")\n",
    "\n",
    "# mlflow.end_run()"
   ]
  },
  {
   "source": [
    "The values already stored in the current Run:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "data = client.get_run(mlflow.active_run().info.run_id).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<RunData: metrics={'foo': 2.857915686374059}, params={'param1': '14'}, tags={'mlflow.runName': 'run0',\n 'mlflow.source.name': '/local/pkg/python/root-python-3.7/lib/python3.7/site-packages/ipykernel_launcher.py',\n 'mlflow.source.type': 'LOCAL',\n 'mlflow.user': 'frahimi'}>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'foo': 2.857915686374059}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "[1. Machine Learning Lifecycle Management Tools](https://medium.com/@esteves.um/machine-learning-lifecycle-management-tools-a97e40d6b0e4)      \n",
    "[2. Operationalizing AI — Managing the End-to-End Lifecycle of AI](https://medium.com/inside-machine-learning/ai-ops-managing-the-end-to-end-lifecycle-of-ai-3606a59591b0)       \n",
    "[3. Tracking ML Experiments using MLflow](https://towardsdatascience.com/tracking-ml-experiments-using-mlflow-7910197091bb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMrH/WNNmB/sAeLLR1hbiz2",
   "collapsed_sections": [],
   "name": "mlflowtracking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}